{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "import logging\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName('spam')\n",
    "sc=SparkContext(conf=conf)\n",
    "sql=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger=logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter=logging.Formatter('%(asctime)s:%(created)f:%(filename)s:%(message)s:%(message)s')\n",
    "file_handler=logging.FileHandler('spam.log')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi=sql.read.options(header=False,inferschema=True,sep=\"\\t\").csv('hdfs://nameservice1/user/edureka_37986/SMSSpamCollection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit=fi.withColumnRenamed('_c0','status').withColumnRenamed('_c1','message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit.registerTempTable('fita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fita = sql.sql('select case when status = \"ham\" then 1.0  else 0 end as label, message from fita')\n",
    "#fita.show(5, truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token=Tokenizer(inputCol=\"message\",outputCol=\"Words\")\n",
    "w=token.transform(fita)\n",
    "#w.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=CountVectorizer(inputCol='Words',outputCol='features').fit(w).transform(w)\n",
    "#count.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf=IDF(inputCol=\"features\",outputCol=\"idf_features\").fit(count).transform(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=0\n",
    "test,train=idf.randomSplit([0.8,0.2],seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e467d3a22aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(labelCol=\"label\",featuresCol=\"idf_features\")\n",
    "model=lr.fit(train)\n",
    "predict=model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval=MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\").evaluate(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949438202247\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Logistic Regression is %g\" %eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|        idf_features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(13587,[0,4,11,12...|\n",
      "|       0.0|  0.0|(13587,[4,10,20,5...|\n",
      "|       0.0|  0.0|(13587,[0,4,5,8,1...|\n",
      "|       0.0|  0.0|(13587,[0,2,7,24,...|\n",
      "|       0.0|  0.0|(13587,[0,2,3,10,...|\n",
      "|       1.0|  0.0|(13587,[353,387,8...|\n",
      "|       0.0|  0.0|(13587,[0,3,4,7,1...|\n",
      "|       1.0|  0.0|(13587,[0,3,10,16...|\n",
      "|       0.0|  0.0|(13587,[224,665,7...|\n",
      "|       0.0|  0.0|(13587,[0,6,24,28...|\n",
      "|       1.0|  0.0|(13587,[0,5,12,20...|\n",
      "|       1.0|  0.0|(13587,[0,4,5,6,1...|\n",
      "|       1.0|  0.0|(13587,[0,4,5,6,1...|\n",
      "|       0.0|  0.0|(13587,[0,5,10,16...|\n",
      "|       1.0|  0.0|(13587,[5831,5893...|\n",
      "|       1.0|  0.0|(13587,[0,4,5,6,1...|\n",
      "|       1.0|  0.0|(13587,[0,8,10,16...|\n",
      "|       1.0|  0.0|(13587,[0,10,11,1...|\n",
      "|       1.0|  0.0|(13587,[0,10,11,5...|\n",
      "|       0.0|  0.0|(13587,[0,2,3,14,...|\n",
      "|       0.0|  0.0|(13587,[0,11,15,1...|\n",
      "|       0.0|  0.0|(13587,[0,3,15,34...|\n",
      "|       0.0|  0.0|(13587,[0,40,64,8...|\n",
      "|       0.0|  0.0|(13587,[0,40,64,8...|\n",
      "|       1.0|  0.0|(13587,[0,8,10,16...|\n",
      "|       0.0|  0.0|(13587,[0,20,28,5...|\n",
      "|       1.0|  0.0|(13587,[0,8,10,16...|\n",
      "|       0.0|  0.0|(13587,[0,6,10,28...|\n",
      "|       0.0|  0.0|(13587,[2,7,11,20...|\n",
      "|       1.0|  0.0|(13587,[329,10723...|\n",
      "|       1.0|  0.0|(13587,[40,328,10...|\n",
      "|       0.0|  0.0|(13587,[0,2,6,7,1...|\n",
      "|       0.0|  0.0|(13587,[7,10,15,4...|\n",
      "|       0.0|  0.0|(13587,[0,4,35,40...|\n",
      "|       1.0|  0.0|(13587,[0,2,3,11,...|\n",
      "|       0.0|  0.0|(13587,[0,2,3,7,1...|\n",
      "|       0.0|  0.0|(13587,[0,2,3,7,1...|\n",
      "|       1.0|  0.0|(13587,[1,3,8,29,...|\n",
      "|       1.0|  0.0|(13587,[2,11,30,3...|\n",
      "|       1.0|  0.0|(13587,[5,20,28,3...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict.select('prediction','label','idf_features').show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "lr=DecisionTreeClassifier(labelCol='label',featuresCol='idf_features')\n",
    "model=lr.fit(train)\n",
    "predict=model.transform(test)\n",
    "eval=MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy').evaluate(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938876404494\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Decision Tree is %g\" %eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomforestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(labelCol='label',featuresCol='idf_features')\n",
    "model=rf.fit(train)\n",
    "predict=model.transform(test)\n",
    "eval=MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy').evaluate(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is 0.864719\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Random Forest is %g\" %eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
