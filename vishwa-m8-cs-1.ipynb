{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "import logging\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName('spam')\n",
    "sc=SparkContext(conf=conf)\n",
    "sql=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger=logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter=logging.Formatter('%(asctime)s:%(created)f:%(filename)s:%(message)s:%(message)s')\n",
    "file_handler=logging.FileHandler('spam.log')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi=sql.read.options(header=False,inferschema=True,sep=\"\\t\").csv('hdfs://nameservice1/user/edureka_396003/SMSSpamCollection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit=fi.withColumnRenamed('_c0','status').withColumnRenamed('_c1','message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit.registerTempTable('fita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  1.0|Go until jurong p...|\n",
      "|  1.0|Ok lar... Joking ...|\n",
      "|  0.0|Free entry in 2 a...|\n",
      "|  1.0|U dun say so earl...|\n",
      "|  1.0|Nah I don't think...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fita = sql.sql('select case when status = \"ham\" then 1.0  else 0 end as label, message from fita')\n",
    "fita.show(5, truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|             message|               Words|\n",
      "+-----+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don't, t...|\n",
      "|  0.0|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|  1.0|Even my brother i...|[even, my, brothe...|\n",
      "|  1.0|As per your reque...|[as, per, your, r...|\n",
      "|  0.0|WINNER!! As a val...|[winner!!, as, a,...|\n",
      "|  0.0|Had your mobile 1...|[had, your, mobil...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token=Tokenizer(inputCol=\"message\",outputCol=\"Words\")\n",
    "w=token.transform(fita)\n",
    "w.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|             message|               Words|            filtered|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|[ok, lar..., joki...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don't, t...|[nah, don't, thin...|\n",
      "|  0.0|FreeMsg Hey there...|[freemsg, hey, th...|[freemsg, hey, da...|\n",
      "|  1.0|Even my brother i...|[even, my, brothe...|[even, brother, l...|\n",
      "|  1.0|As per your reque...|[as, per, your, r...|[per, request, 'm...|\n",
      "|  0.0|WINNER!! As a val...|[winner!!, as, a,...|[winner!!, valued...|\n",
      "|  0.0|Had your mobile 1...|[had, your, mobil...|[mobile, 11, mont...|\n",
      "|  1.0|I'm gonna be home...|[i'm, gonna, be, ...|[i'm, gonna, home...|\n",
      "|  0.0|SIX chances to wi...|[six, chances, to...|[six, chances, wi...|\n",
      "|  0.0|URGENT! You have ...|[urgent!, you, ha...|[urgent!, 1, week...|\n",
      "|  1.0|I've been searchi...|[i've, been, sear...|[i've, searching,...|\n",
      "|  1.0|I HAVE A DATE ON ...|[i, have, a, date...|[date, sunday, wi...|\n",
      "|  0.0|XXXMobileMovieClu...|[xxxmobilemoviecl...|[xxxmobilemoviecl...|\n",
      "|  1.0|Oh k...i'm watchi...|[oh, k...i'm, wat...|[oh, k...i'm, wat...|\n",
      "|  1.0|Eh u remember how...|[eh, u, remember,...|[eh, u, remember,...|\n",
      "|  1.0|Fine if thats th...|[fine, if, thats...|[fine, thats, wa...|\n",
      "|  0.0|England v Macedon...|[england, v, mace...|[england, v, mace...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "remover=StopWordsRemover().setInputCol('Words').setOutputCol('filtered')\n",
    "cleaned=remover.transform(w)\n",
    "cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|             message|               Words|            filtered|       filtered_word|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|[go, jurong, poin...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|[ok, lar..., joki...|[ok, lar..., joki...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|[free, entry, 2, ...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|[u, dun, say, ear...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don't, t...|[nah, don't, thin...|[nah, don't, thin...|\n",
      "|  0.0|FreeMsg Hey there...|[freemsg, hey, th...|[freemsg, hey, da...|[freemsg, hey, da...|\n",
      "|  1.0|Even my brother i...|[even, my, brothe...|[even, brother, l...|[even, brother, l...|\n",
      "|  1.0|As per your reque...|[as, per, your, r...|[per, request, 'm...|[per, request, 'm...|\n",
      "|  0.0|WINNER!! As a val...|[winner!!, as, a,...|[winner!!, valued...|[winner!!, valued...|\n",
      "|  0.0|Had your mobile 1...|[had, your, mobil...|[mobile, 11, mont...|[mobile, 11, mont...|\n",
      "|  1.0|I'm gonna be home...|[i'm, gonna, be, ...|[i'm, gonna, home...|[i'm, gonna, home...|\n",
      "|  0.0|SIX chances to wi...|[six, chances, to...|[six, chances, wi...|[six, chances, wi...|\n",
      "|  0.0|URGENT! You have ...|[urgent!, you, ha...|[urgent!, 1, week...|[urgent!, 1, week...|\n",
      "|  1.0|I've been searchi...|[i've, been, sear...|[i've, searching,...|[i've, searching,...|\n",
      "|  1.0|I HAVE A DATE ON ...|[i, have, a, date...|[date, sunday, wi...|[date, sunday, wi...|\n",
      "|  0.0|XXXMobileMovieClu...|[xxxmobilemoviecl...|[xxxmobilemoviecl...|[xxxmobilemoviecl...|\n",
      "|  1.0|Oh k...i'm watchi...|[oh, k...i'm, wat...|[oh, k...i'm, wat...|[oh, k...i'm, wat...|\n",
      "|  1.0|Eh u remember how...|[eh, u, remember,...|[eh, u, remember,...|[eh, u, remember,...|\n",
      "|  1.0|Fine if thats th...|[fine, if, thats...|[fine, thats, wa...|[fine, thats, wa...|\n",
      "|  0.0|England v Macedon...|[england, v, mace...|[england, v, mace...|[england, v, mace...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopwords=StopWordsRemover().getStopWords() + ['-','.']\n",
    "remover=StopWordsRemover().setStopWords(stopwords).setInputCol('Words').setOutputCol('filtered_word')\n",
    "cleaned_custom=remover.transform(cleaned)\n",
    "cleaned_custom.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|             message|               Words|            features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|(13587,[8,42,52,6...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|(13587,[5,75,411,...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|(13587,[0,3,8,20,...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|(13587,[5,22,60,1...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count=CountVectorizer(inputCol='Words',outputCol='features').fit(w).transform(w)\n",
    "count.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf=IDF(inputCol=\"features\",outputCol=\"idf_features\").fit(count).transform(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=0\n",
    "test,train=idf.randomSplit([0.8,0.2],seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|             message|               Words|            features|        idf_features|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0.0|(Bank of Granite ...|[(bank, of, grani...|(13587,[3,7,10,12...|(13587,[3,7,10,12...|\n",
      "|  0.0|+123 Congratulati...|[+123, congratula...|(13587,[0,4,5,8,1...|(13587,[0,4,5,8,1...|\n",
      "|  0.0|+449071512431 URG...|[+449071512431, u...|(13587,[0,4,7,14,...|(13587,[0,4,7,14,...|\n",
      "|  0.0|3. You have recei...|[3., you, have, r...|(13587,[2,11,14,9...|(13587,[2,11,14,9...|\n",
      "|  0.0|44 7732584351, Do...|[44, 7732584351,,...|(13587,[0,2,3,15,...|(13587,[0,2,3,15,...|\n",
      "|  0.0|4mths half price ...|[4mths, half, pri...|(13587,[0,11,15,1...|(13587,[0,11,15,1...|\n",
      "|  0.0|4mths half price ...|[4mths, half, pri...|(13587,[0,11,15,1...|(13587,[0,11,15,1...|\n",
      "|  0.0|500 free text msg...|[500, free, text,...|(13587,[0,6,11,35...|(13587,[0,6,11,35...|\n",
      "|  0.0|87077: Kick off a...|[87077:, kick, of...|(13587,[0,3,28,31...|(13587,[0,3,28,31...|\n",
      "|  0.0|88800 and 89034 a...|[88800, and, 8903...|(13587,[6,15,17,1...|(13587,[6,15,17,1...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(10,truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(labelCol=\"label\",featuresCol=\"idf_features\")\n",
    "model=lr.fit(train)\n",
    "predict=model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval=MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\").evaluate(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949438202247\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Logistic Regression is %g\" %eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|        idf_features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(13587,[0,4,11,12...|\n",
      "|       0.0|  0.0|(13587,[4,10,20,5...|\n",
      "|       0.0|  0.0|(13587,[0,4,5,8,1...|\n",
      "|       0.0|  0.0|(13587,[0,2,7,24,...|\n",
      "|       0.0|  0.0|(13587,[0,2,3,10,...|\n",
      "|       1.0|  0.0|(13587,[353,387,8...|\n",
      "|       0.0|  0.0|(13587,[0,3,4,7,1...|\n",
      "|       1.0|  0.0|(13587,[0,3,10,16...|\n",
      "|       0.0|  0.0|(13587,[224,665,7...|\n",
      "|       0.0|  0.0|(13587,[0,6,24,28...|\n",
      "|       1.0|  0.0|(13587,[0,5,12,20...|\n",
      "|       1.0|  0.0|(13587,[0,4,5,6,1...|\n",
      "|       1.0|  0.0|(13587,[0,4,5,6,1...|\n",
      "|       0.0|  0.0|(13587,[0,5,10,16...|\n",
      "|       1.0|  0.0|(13587,[5831,5893...|\n",
      "|       1.0|  0.0|(13587,[0,4,5,6,1...|\n",
      "|       1.0|  0.0|(13587,[0,8,10,16...|\n",
      "|       1.0|  0.0|(13587,[0,10,11,1...|\n",
      "|       1.0|  0.0|(13587,[0,10,11,5...|\n",
      "|       0.0|  0.0|(13587,[0,2,3,14,...|\n",
      "|       0.0|  0.0|(13587,[0,11,15,1...|\n",
      "|       0.0|  0.0|(13587,[0,3,15,34...|\n",
      "|       0.0|  0.0|(13587,[0,40,64,8...|\n",
      "|       0.0|  0.0|(13587,[0,40,64,8...|\n",
      "|       1.0|  0.0|(13587,[0,8,10,16...|\n",
      "|       0.0|  0.0|(13587,[0,20,28,5...|\n",
      "|       1.0|  0.0|(13587,[0,8,10,16...|\n",
      "|       0.0|  0.0|(13587,[0,6,10,28...|\n",
      "|       0.0|  0.0|(13587,[2,7,11,20...|\n",
      "|       1.0|  0.0|(13587,[329,10723...|\n",
      "|       1.0|  0.0|(13587,[40,328,10...|\n",
      "|       0.0|  0.0|(13587,[0,2,6,7,1...|\n",
      "|       0.0|  0.0|(13587,[7,10,15,4...|\n",
      "|       0.0|  0.0|(13587,[0,4,35,40...|\n",
      "|       1.0|  0.0|(13587,[0,2,3,11,...|\n",
      "|       0.0|  0.0|(13587,[0,2,3,7,1...|\n",
      "|       0.0|  0.0|(13587,[0,2,3,7,1...|\n",
      "|       1.0|  0.0|(13587,[1,3,8,29,...|\n",
      "|       1.0|  0.0|(13587,[2,11,30,3...|\n",
      "|       1.0|  0.0|(13587,[5,20,28,3...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict.select('prediction','label','idf_features').show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "lr=DecisionTreeClassifier(labelCol='label',featuresCol='idf_features')\n",
    "model=lr.fit(train)\n",
    "predict=model.transform(test)\n",
    "eval=MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy').evaluate(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938876404494\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Decision Tree is %g\" %eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomforestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(labelCol='label',featuresCol='idf_features')\n",
    "model=rf.fit(train)\n",
    "predict=model.transform(test)\n",
    "eval=MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy').evaluate(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is 0.864719\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Random Forest is %g\" %eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|             message|               Words|            filtered|       filtered_word|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|[go, jurong, poin...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|[ok, lar..., joki...|[ok, lar..., joki...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "cleaned_custom.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|             message|               Words|            filtered|       filtered_word|              ngrams|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|[go, jurong, poin...|[go jurong, juron...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|[ok, lar..., joki...|[ok, lar..., joki...|[ok lar..., lar.....|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = NGram(n=2, inputCol=\"filtered_word\", outputCol=\"ngrams\")\n",
    "ngramDataFrame = ngram.transform(cleaned_custom)\n",
    "ngramDataFrame.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
